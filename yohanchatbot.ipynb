{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10033531,"sourceType":"datasetVersion","datasetId":6179897},{"sourceId":10033564,"sourceType":"datasetVersion","datasetId":6179914}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, Input, Dense, LSTM, LayerNormalization, MultiHeadAttention\nfrom tensorflow.keras.models import Model\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:03.013392Z","iopub.execute_input":"2024-12-03T18:35:03.013755Z","iopub.status.idle":"2024-12-03T18:35:06.349051Z","shell.execute_reply.started":"2024-12-03T18:35:03.013726Z","shell.execute_reply":"2024-12-03T18:35:06.347988Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n# 1. Data Preparation\n# Load the CSV file and process conversations\ndf = pd.read_csv('/kaggle/input/chatdata3/chat_data.csv',nrows=10000)","metadata":{"_uuid":"8d7d8697-0e47-4a3d-9274-b04a1fdef90b","_cell_guid":"d7551b1e-0aa2-4c0f-b57e-d6b2216e87d4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T18:35:09.403194Z","iopub.execute_input":"2024-12-03T18:35:09.404279Z","iopub.status.idle":"2024-12-03T18:35:09.849273Z","shell.execute_reply.started":"2024-12-03T18:35:09.404241Z","shell.execute_reply":"2024-12-03T18:35:09.848332Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\npattern = r\"'value':\\s\\\"(.*?)\\\"\"\n\nfinal_data = {'Column 1': [], 'Column 2': []}\nfor input_string in df['conversations']:\n    messages = re.findall(pattern, input_string)\n    temp_data = {'Column 1': [], 'Column 2': []}\n    for i, message in enumerate(messages):\n        if i % 2 == 0:\n            temp_data['Column 1'].append(message)\n            temp_data['Column 2'].append('')\n        else:\n            temp_data['Column 2'][-1] = message\n    final_data['Column 1'].extend(temp_data['Column 1'])\n    final_data['Column 2'].extend(temp_data['Column 2'])\n\nfinal_data = pd.DataFrame(final_data)","metadata":{"_uuid":"6adbcd78-6ca7-451e-a233-8aaf5f8784d5","_cell_guid":"d72b2d02-f52a-4389-a56d-9c304716a8b1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-03T18:35:10.081993Z","iopub.execute_input":"2024-12-03T18:35:10.082364Z","iopub.status.idle":"2024-12-03T18:35:10.825507Z","shell.execute_reply.started":"2024-12-03T18:35:10.082302Z","shell.execute_reply":"2024-12-03T18:35:10.824559Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"final_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:12.241062Z","iopub.execute_input":"2024-12-03T18:35:12.241710Z","iopub.status.idle":"2024-12-03T18:35:12.253294Z","shell.execute_reply.started":"2024-12-03T18:35:12.241674Z","shell.execute_reply":"2024-12-03T18:35:12.252377Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                Column 1  \\\n0      I've been feeling so sad and overwhelmed latel...   \n1      I recently got a promotion at work, which I th...   \n2      Well, the workload has increased significantly...   \n3      I've been trying to prioritize my tasks and de...   \n4      You're right. I haven't really opened up about...   \n...                                                  ...   \n70274  Great! Let's start by finding a quiet and comf...   \n70275  That's wonderful, Charlie. Remember, it's norm...   \n70276  You're very welcome, Charlie. I'm glad I could...   \n70277  I'm so glad to hear that, Charlie. Remember, t...   \n70278  You're most welcome, Charlie. Take care of you...   \n\n                                                Column 2  \n0      Hey there, I'm here to listen and support you....  \n1      I can understand how it can be overwhelming wh...  \n2      It sounds like you're dealing with a lot of pr...  \n3      It's great to hear that you're already impleme...  \n4      It's completely normal to feel that way, but r...  \n...                                                  ...  \n70274  (Takes a deep breath) I'm starting to feel a b...  \n70275  I'll keep that in mind. This feels like someth...  \n70276  I truly appreciate your support, Alex. You've ...  \n70277  Thank you, Alex. Your warmth and guidance mean...  \n70278                                                     \n\n[70279 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column 1</th>\n      <th>Column 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I've been feeling so sad and overwhelmed latel...</td>\n      <td>Hey there, I'm here to listen and support you....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I recently got a promotion at work, which I th...</td>\n      <td>I can understand how it can be overwhelming wh...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Well, the workload has increased significantly...</td>\n      <td>It sounds like you're dealing with a lot of pr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I've been trying to prioritize my tasks and de...</td>\n      <td>It's great to hear that you're already impleme...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You're right. I haven't really opened up about...</td>\n      <td>It's completely normal to feel that way, but r...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70274</th>\n      <td>Great! Let's start by finding a quiet and comf...</td>\n      <td>(Takes a deep breath) I'm starting to feel a b...</td>\n    </tr>\n    <tr>\n      <th>70275</th>\n      <td>That's wonderful, Charlie. Remember, it's norm...</td>\n      <td>I'll keep that in mind. This feels like someth...</td>\n    </tr>\n    <tr>\n      <th>70276</th>\n      <td>You're very welcome, Charlie. I'm glad I could...</td>\n      <td>I truly appreciate your support, Alex. You've ...</td>\n    </tr>\n    <tr>\n      <th>70277</th>\n      <td>I'm so glad to hear that, Charlie. Remember, t...</td>\n      <td>Thank you, Alex. Your warmth and guidance mean...</td>\n    </tr>\n    <tr>\n      <th>70278</th>\n      <td>You're most welcome, Charlie. Take care of you...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>70279 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Combine both columns into a single text chunk\ncombined_full_text = \" \".join(final_data[\"Column 1\"].fillna(\"\") + \" \" + final_data[\"Column 2\"].fillna(\"\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:13.043262Z","iopub.execute_input":"2024-12-03T18:35:13.044136Z","iopub.status.idle":"2024-12-03T18:35:13.208243Z","shell.execute_reply.started":"2024-12-03T18:35:13.044102Z","shell.execute_reply":"2024-12-03T18:35:13.207289Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"len(combined_full_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:13.514250Z","iopub.execute_input":"2024-12-03T18:35:13.514948Z","iopub.status.idle":"2024-12-03T18:35:13.520093Z","shell.execute_reply.started":"2024-12-03T18:35:13.514914Z","shell.execute_reply":"2024-12-03T18:35:13.519348Z"},"scrolled":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"33859914"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# !python -m pip install contractions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:14.748200Z","iopub.execute_input":"2024-12-03T18:35:14.748568Z","iopub.status.idle":"2024-12-03T18:35:14.752382Z","shell.execute_reply.started":"2024-12-03T18:35:14.748540Z","shell.execute_reply":"2024-12-03T18:35:14.751516Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"combined_text = combined_full_text[:300000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:15.142215Z","iopub.execute_input":"2024-12-03T18:35:15.142894Z","iopub.status.idle":"2024-12-03T18:35:15.146680Z","shell.execute_reply.started":"2024-12-03T18:35:15.142863Z","shell.execute_reply":"2024-12-03T18:35:15.145784Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"len(combined_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:15.488685Z","iopub.execute_input":"2024-12-03T18:35:15.489345Z","iopub.status.idle":"2024-12-03T18:35:15.494612Z","shell.execute_reply.started":"2024-12-03T18:35:15.489301Z","shell.execute_reply":"2024-12-03T18:35:15.493500Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"300000"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'combined_text' is already created\nwords = combined_text.split()  # Split the text into individual words\n\n# Create input-output pairs\nsequence_length = 10\ninput_output_pairs = []\n\nfor i in range(len(words) - sequence_length):\n    input_sequence = \" \".join(words[i:i + sequence_length])  # 10 words as input\n    output_word = words[i + sequence_length]  # 11th word as output\n    input_output_pairs.append((input_sequence, output_word))\n\n# Convert to DataFrame for better visualization and handling\ninput_output_df = pd.DataFrame(input_output_pairs, columns=[\"Input\", \"Output\"])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:15.949106Z","iopub.execute_input":"2024-12-03T18:35:15.949710Z","iopub.status.idle":"2024-12-03T18:35:16.005657Z","shell.execute_reply.started":"2024-12-03T18:35:15.949676Z","shell.execute_reply":"2024-12-03T18:35:16.005010Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\ninput_output_df[\"Output\"][0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:16.308159Z","iopub.execute_input":"2024-12-03T18:35:16.308518Z","iopub.status.idle":"2024-12-03T18:35:16.314444Z","shell.execute_reply.started":"2024-12-03T18:35:16.308489Z","shell.execute_reply":"2024-12-03T18:35:16.313548Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'become'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"input_output_df[\"Input\"][0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:16.649950Z","iopub.execute_input":"2024-12-03T18:35:16.650782Z","iopub.status.idle":"2024-12-03T18:35:16.655727Z","shell.execute_reply.started":"2024-12-03T18:35:16.650748Z","shell.execute_reply":"2024-12-03T18:35:16.655053Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"\"I've been feeling so sad and overwhelmed lately. Work has\""},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\n\n# Tokenizing the text\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(input_output_df[\"Input\"]) \n\n# Filter out rows with empty output sequences\nfiltered_pairs = [\n    (input_seq, output_word)\n    for input_seq, output_word in zip(input_output_df[\"Input\"], input_output_df[\"Output\"])\n    if tokenizer.texts_to_sequences([output_word])[0]  # Check if the output word is in the vocabulary\n]\n\n# Extract the filtered input and output\nfiltered_inputs, filtered_outputs = zip(*filtered_pairs)\n\n# Convert text to sequences\ninput_sequences = tokenizer.texts_to_sequences(filtered_inputs)\noutput_words = tokenizer.texts_to_sequences(filtered_outputs)\n\n# Pad input sequences\nmax_length = max(len(seq) for seq in input_sequences)\ninput_sequences = pad_sequences(input_sequences, maxlen=max_length, padding=\"post\")\n\n# Convert output to categorical\nvocab_size = len(tokenizer.word_index) + 1\noutput_words = np.array([seq[0] for seq in output_words])  # Convert output to 1D array\noutput_words = to_categorical(output_words, num_classes=vocab_size)\n\nprint(f\"Vocabulary size: {vocab_size}, Input shape: {input_sequences.shape}, Output shape: {output_words.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:17.113166Z","iopub.execute_input":"2024-12-03T18:35:17.113865Z","iopub.status.idle":"2024-12-03T18:35:19.115239Z","shell.execute_reply.started":"2024-12-03T18:35:17.113832Z","shell.execute_reply":"2024-12-03T18:35:19.114400Z"}},"outputs":[{"name":"stdout","text":"Vocabulary size: 2881, Input shape: (50232, 13), Output shape: (50232, 2881)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(input_sequences, output_words, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:19.116568Z","iopub.execute_input":"2024-12-03T18:35:19.116841Z","iopub.status.idle":"2024-12-03T18:35:19.780906Z","shell.execute_reply.started":"2024-12-03T18:35:19.116816Z","shell.execute_reply":"2024-12-03T18:35:19.780184Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Define the Transformer block\nclass TransformerBlock(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n        super(TransformerBlock, self).__init__(**kwargs)\n        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = tf.keras.Sequential([\n            tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n            tf.keras.layers.Dense(embed_dim),\n        ])\n        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n        self.dropout1 = Dropout(rate)\n        self.dropout2 = Dropout(rate)\n\n    def call(self, inputs, training=None):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)\n\n    def get_config(self):\n        config = super(TransformerBlock, self).get_config()\n        config.update({\n            \"embed_dim\": self.att.key_dim,\n            \"num_heads\": self.att.num_heads,\n            \"ff_dim\": self.ffn.layers[0].units,\n            \"rate\": self.dropout1.rate,\n        })\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n# Positional encoding\nclass PositionalEncoding(tf.keras.layers.Layer):\n    def __init__(self, max_len, embed_dim, **kwargs):\n        super(PositionalEncoding, self).__init__(**kwargs)\n        self.positional_encoding = self.get_positional_encoding(max_len, embed_dim)\n\n    def get_positional_encoding(self, max_len, embed_dim):\n        pos = np.arange(max_len)[:, np.newaxis]\n        i = np.arange(embed_dim)[np.newaxis, :]\n        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(embed_dim))\n        angle_rads = pos * angle_rates\n        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])  # Apply sin to even indices\n        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  # Apply cos to odd indices\n        return tf.constant(angle_rads, dtype=tf.float32)\n\n    def call(self, inputs):\n        return inputs + self.positional_encoding[: tf.shape(inputs)[1], :]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:19.781961Z","iopub.execute_input":"2024-12-03T18:35:19.782232Z","iopub.status.idle":"2024-12-03T18:35:19.792592Z","shell.execute_reply.started":"2024-12-03T18:35:19.782206Z","shell.execute_reply":"2024-12-03T18:35:19.791746Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Embedding, Dropout, Dense, GlobalAveragePooling1D, LayerNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n\nembed_dim = 64  # Embedding size\nnum_heads = 4   # Number of attention heads\nff_dim = 128    # Feed-forward network dimension\ndropout_rate = 0.5  # Dropout rate\n\ninputs = Input(shape=(max_length,))\nx = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\nx = PositionalEncoding(max_len=max_length, embed_dim=embed_dim)(x)\ntransformer_block = TransformerBlock(embed_dim, num_heads, ff_dim, rate=dropout_rate)\nx = transformer_block(x)\nx = GlobalAveragePooling1D()(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dropout(dropout_rate)(x)\n\noutputs = Dense(vocab_size, activation=\"softmax\")(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nprint(model.summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:20.415820Z","iopub.execute_input":"2024-12-03T18:35:20.417022Z","iopub.status.idle":"2024-12-03T18:35:21.346280Z","shell.execute_reply.started":"2024-12-03T18:35:20.416972Z","shell.execute_reply":"2024-12-03T18:35:21.345377Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m184,384\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_encoding             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m83,200\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2881\u001b[0m)           │       \u001b[38;5;34m187,265\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">184,384</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_encoding             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2881</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">187,265</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m459,009\u001b[0m (1.75 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">459,009</span> (1.75 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m459,009\u001b[0m (1.75 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">459,009</span> (1.75 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    X_train,\n    y_train,\n    batch_size=32,\n    epochs=100,\n    validation_data=(X_test, y_test)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:35:21.347700Z","iopub.execute_input":"2024-12-03T18:35:21.347984Z","iopub.status.idle":"2024-12-03T18:41:59.973796Z","shell.execute_reply.started":"2024-12-03T18:35:21.347956Z","shell.execute_reply":"2024-12-03T18:41:59.972782Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733250925.504912    2671 service.cc:145] XLA service 0x7f94f0006e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733250925.504965    2671 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1733250925.504971    2671 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733250930.501616    2697 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_42', 8 bytes spill stores, 8 bytes spill loads\n\nI0000 00:00:1733250933.125944    2699 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_40', 132 bytes spill stores, 132 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  55/1256\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0283 - loss: 7.6625 ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1733250937.509122    2671 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1238/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0408 - loss: 6.4862","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1733250944.676292    2734 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_42', 8 bytes spill stores, 8 bytes spill loads\n\nI0000 00:00:1733250949.240901    2733 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_40', 132 bytes spill stores, 132 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0408 - loss: 6.4833","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1733250959.028923    2775 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_8', 132 bytes spill stores, 132 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 18ms/step - accuracy: 0.0408 - loss: 6.4832 - val_accuracy: 0.0419 - val_loss: 6.0769\nEpoch 2/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0443 - loss: 6.0180 - val_accuracy: 0.0449 - val_loss: 5.9773\nEpoch 3/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0561 - loss: 5.8460 - val_accuracy: 0.0633 - val_loss: 5.9703\nEpoch 4/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0656 - loss: 5.7351 - val_accuracy: 0.0678 - val_loss: 5.9245\nEpoch 5/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0782 - loss: 5.5786 - val_accuracy: 0.0775 - val_loss: 5.9252\nEpoch 6/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0908 - loss: 5.4470 - val_accuracy: 0.0902 - val_loss: 5.7978\nEpoch 7/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1026 - loss: 5.3385 - val_accuracy: 0.1047 - val_loss: 5.7041\nEpoch 8/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1079 - loss: 5.2628 - val_accuracy: 0.1154 - val_loss: 5.8784\nEpoch 9/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1186 - loss: 5.1819 - val_accuracy: 0.1211 - val_loss: 5.7386\nEpoch 10/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1255 - loss: 5.0807 - val_accuracy: 0.1266 - val_loss: 5.7084\nEpoch 11/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1266 - loss: 5.0182 - val_accuracy: 0.1231 - val_loss: 5.7562\nEpoch 12/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1336 - loss: 4.9620 - val_accuracy: 0.1319 - val_loss: 5.9313\nEpoch 13/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1385 - loss: 4.9025 - val_accuracy: 0.1306 - val_loss: 5.7654\nEpoch 14/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1373 - loss: 4.8411 - val_accuracy: 0.1330 - val_loss: 5.9047\nEpoch 15/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1428 - loss: 4.7665 - val_accuracy: 0.1363 - val_loss: 5.7547\nEpoch 16/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1430 - loss: 4.7659 - val_accuracy: 0.1396 - val_loss: 6.0246\nEpoch 17/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1498 - loss: 4.6957 - val_accuracy: 0.1409 - val_loss: 6.0522\nEpoch 18/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1517 - loss: 4.6607 - val_accuracy: 0.1448 - val_loss: 5.9571\nEpoch 19/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1517 - loss: 4.6494 - val_accuracy: 0.1470 - val_loss: 6.0818\nEpoch 20/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1532 - loss: 4.6141 - val_accuracy: 0.1465 - val_loss: 5.9457\nEpoch 21/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1526 - loss: 4.5911 - val_accuracy: 0.1487 - val_loss: 6.2591\nEpoch 22/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1577 - loss: 4.5690 - val_accuracy: 0.1493 - val_loss: 6.3310\nEpoch 23/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1601 - loss: 4.5356 - val_accuracy: 0.1514 - val_loss: 6.2214\nEpoch 24/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1583 - loss: 4.5150 - val_accuracy: 0.1553 - val_loss: 6.3272\nEpoch 25/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1625 - loss: 4.4933 - val_accuracy: 0.1531 - val_loss: 6.5127\nEpoch 26/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1616 - loss: 4.4839 - val_accuracy: 0.1521 - val_loss: 6.5129\nEpoch 27/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1647 - loss: 4.4573 - val_accuracy: 0.1549 - val_loss: 6.3198\nEpoch 28/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1655 - loss: 4.4465 - val_accuracy: 0.1563 - val_loss: 6.5475\nEpoch 29/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1681 - loss: 4.4225 - val_accuracy: 0.1580 - val_loss: 6.4495\nEpoch 30/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1692 - loss: 4.4004 - val_accuracy: 0.1586 - val_loss: 6.6129\nEpoch 31/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1734 - loss: 4.3806 - val_accuracy: 0.1594 - val_loss: 6.7113\nEpoch 32/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1720 - loss: 4.3698 - val_accuracy: 0.1589 - val_loss: 6.6584\nEpoch 33/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1780 - loss: 4.3461 - val_accuracy: 0.1613 - val_loss: 6.8355\nEpoch 34/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1757 - loss: 4.3466 - val_accuracy: 0.1612 - val_loss: 6.8102\nEpoch 35/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1787 - loss: 4.3259 - val_accuracy: 0.1635 - val_loss: 6.6095\nEpoch 36/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1782 - loss: 4.3183 - val_accuracy: 0.1651 - val_loss: 6.8416\nEpoch 37/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1789 - loss: 4.3194 - val_accuracy: 0.1627 - val_loss: 6.5870\nEpoch 38/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1732 - loss: 4.3089 - val_accuracy: 0.1646 - val_loss: 6.9759\nEpoch 39/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1813 - loss: 4.2916 - val_accuracy: 0.1618 - val_loss: 6.8178\nEpoch 40/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1812 - loss: 4.2791 - val_accuracy: 0.1645 - val_loss: 6.8235\nEpoch 41/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1829 - loss: 4.2725 - val_accuracy: 0.1653 - val_loss: 7.0464\nEpoch 42/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1867 - loss: 4.2572 - val_accuracy: 0.1666 - val_loss: 7.2276\nEpoch 43/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1813 - loss: 4.2612 - val_accuracy: 0.1660 - val_loss: 6.9538\nEpoch 44/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1814 - loss: 4.2548 - val_accuracy: 0.1649 - val_loss: 6.8147\nEpoch 45/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1812 - loss: 4.2555 - val_accuracy: 0.1721 - val_loss: 6.9313\nEpoch 46/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1893 - loss: 4.2226 - val_accuracy: 0.1667 - val_loss: 7.1588\nEpoch 47/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1869 - loss: 4.2311 - val_accuracy: 0.1672 - val_loss: 7.6608\nEpoch 48/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1877 - loss: 4.2082 - val_accuracy: 0.1708 - val_loss: 7.3967\nEpoch 49/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1886 - loss: 4.2069 - val_accuracy: 0.1705 - val_loss: 7.3895\nEpoch 50/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1891 - loss: 4.1940 - val_accuracy: 0.1675 - val_loss: 7.0799\nEpoch 51/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1856 - loss: 4.2026 - val_accuracy: 0.1700 - val_loss: 7.2982\nEpoch 52/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1901 - loss: 4.1799 - val_accuracy: 0.1710 - val_loss: 7.4307\nEpoch 53/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1919 - loss: 4.1664 - val_accuracy: 0.1696 - val_loss: 7.4650\nEpoch 54/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1870 - loss: 4.1764 - val_accuracy: 0.1689 - val_loss: 7.6279\nEpoch 55/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1919 - loss: 4.1667 - val_accuracy: 0.1702 - val_loss: 7.4473\nEpoch 56/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1947 - loss: 4.1601 - val_accuracy: 0.1692 - val_loss: 7.6869\nEpoch 57/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1933 - loss: 4.1299 - val_accuracy: 0.1692 - val_loss: 7.3484\nEpoch 58/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1966 - loss: 4.1450 - val_accuracy: 0.1712 - val_loss: 7.6187\nEpoch 59/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1909 - loss: 4.1602 - val_accuracy: 0.1722 - val_loss: 7.6899\nEpoch 60/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1985 - loss: 4.1273 - val_accuracy: 0.1710 - val_loss: 7.3644\nEpoch 61/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1958 - loss: 4.1358 - val_accuracy: 0.1733 - val_loss: 7.4992\nEpoch 62/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1977 - loss: 4.1441 - val_accuracy: 0.1743 - val_loss: 7.5703\nEpoch 63/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1976 - loss: 4.1459 - val_accuracy: 0.1730 - val_loss: 7.5973\nEpoch 64/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2002 - loss: 4.1087 - val_accuracy: 0.1745 - val_loss: 7.6375\nEpoch 65/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1972 - loss: 4.1156 - val_accuracy: 0.1719 - val_loss: 7.6170\nEpoch 66/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2006 - loss: 4.1085 - val_accuracy: 0.1729 - val_loss: 7.9445\nEpoch 67/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2012 - loss: 4.1041 - val_accuracy: 0.1697 - val_loss: 7.9430\nEpoch 68/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2019 - loss: 4.1011 - val_accuracy: 0.1691 - val_loss: 7.9705\nEpoch 69/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2025 - loss: 4.0985 - val_accuracy: 0.1730 - val_loss: 7.7520\nEpoch 70/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2063 - loss: 4.0608 - val_accuracy: 0.1734 - val_loss: 7.9447\nEpoch 71/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1990 - loss: 4.1108 - val_accuracy: 0.1727 - val_loss: 7.8024\nEpoch 72/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1994 - loss: 4.0817 - val_accuracy: 0.1747 - val_loss: 7.9399\nEpoch 73/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2019 - loss: 4.0783 - val_accuracy: 0.1766 - val_loss: 8.1421\nEpoch 74/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2022 - loss: 4.0535 - val_accuracy: 0.1697 - val_loss: 8.0467\nEpoch 75/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2042 - loss: 4.0640 - val_accuracy: 0.1733 - val_loss: 7.8611\nEpoch 76/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2037 - loss: 4.0580 - val_accuracy: 0.1781 - val_loss: 7.7346\nEpoch 77/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2054 - loss: 4.0583 - val_accuracy: 0.1775 - val_loss: 7.8036\nEpoch 78/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2032 - loss: 4.0508 - val_accuracy: 0.1753 - val_loss: 7.6330\nEpoch 79/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2056 - loss: 4.0516 - val_accuracy: 0.1728 - val_loss: 7.8809\nEpoch 80/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2049 - loss: 4.0370 - val_accuracy: 0.1744 - val_loss: 8.0647\nEpoch 81/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2060 - loss: 4.0417 - val_accuracy: 0.1774 - val_loss: 7.8470\nEpoch 82/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2021 - loss: 4.0686 - val_accuracy: 0.1757 - val_loss: 8.0359\nEpoch 83/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2066 - loss: 4.0523 - val_accuracy: 0.1752 - val_loss: 8.0357\nEpoch 84/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2079 - loss: 4.0425 - val_accuracy: 0.1764 - val_loss: 7.9285\nEpoch 85/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2048 - loss: 4.0344 - val_accuracy: 0.1733 - val_loss: 7.6629\nEpoch 86/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2054 - loss: 4.0302 - val_accuracy: 0.1743 - val_loss: 7.9567\nEpoch 87/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2081 - loss: 4.0173 - val_accuracy: 0.1775 - val_loss: 8.1739\nEpoch 88/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2138 - loss: 4.0096 - val_accuracy: 0.1767 - val_loss: 8.2670\nEpoch 89/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2065 - loss: 4.0265 - val_accuracy: 0.1764 - val_loss: 7.9240\nEpoch 90/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2088 - loss: 4.0348 - val_accuracy: 0.1754 - val_loss: 8.1356\nEpoch 91/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2068 - loss: 4.0336 - val_accuracy: 0.1799 - val_loss: 8.2559\nEpoch 92/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2058 - loss: 4.0249 - val_accuracy: 0.1769 - val_loss: 7.9750\nEpoch 93/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2076 - loss: 4.0305 - val_accuracy: 0.1796 - val_loss: 7.7007\nEpoch 94/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2082 - loss: 4.0221 - val_accuracy: 0.1755 - val_loss: 8.4108\nEpoch 95/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2095 - loss: 4.0113 - val_accuracy: 0.1767 - val_loss: 7.9585\nEpoch 96/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2119 - loss: 3.9887 - val_accuracy: 0.1768 - val_loss: 8.0143\nEpoch 97/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2104 - loss: 4.0040 - val_accuracy: 0.1772 - val_loss: 8.2574\nEpoch 98/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2111 - loss: 4.0087 - val_accuracy: 0.1780 - val_loss: 7.9723\nEpoch 99/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2115 - loss: 3.9944 - val_accuracy: 0.1774 - val_loss: 7.8991\nEpoch 100/100\n\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2102 - loss: 4.0139 - val_accuracy: 0.1796 - val_loss: 8.0414\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def predict_sequence(initial_text, model, tokenizer, max_length, num_predictions):\n\n    current_text = initial_text\n    \n    for _ in range(num_predictions):\n        # Preprocess the current text\n        input_sequence = tokenizer.texts_to_sequences([current_text])\n        input_sequence = pad_sequences(input_sequence, maxlen=max_length, padding=\"post\")\n        \n        # Predict the next word\n        predicted_probs = model.predict(input_sequence, verbose=0)\n        predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n        predicted_word = tokenizer.index_word.get(predicted_index, \"\")\n        \n        if not predicted_word:  # Stop if no valid prediction\n            break\n        \n        # Update the input text\n        current_text += f\" {predicted_word}\"  # Append the predicted word\n        current_text = \" \".join(current_text.split()[-max_length:])  # Keep only the last max_length words\n\n    return current_text\n\n# Example usage\ninitial_text = \"I've been feeling so sad and\"\ngenerated_sequence = predict_sequence(initial_text, model, tokenizer, max_length, num_predictions=20)\nprint(f\"Generated sequence: {generated_sequence}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:46:22.316669Z","iopub.execute_input":"2024-12-03T18:46:22.317016Z","iopub.status.idle":"2024-12-03T18:46:23.279926Z","shell.execute_reply.started":"2024-12-03T18:46:22.316986Z","shell.execute_reply":"2024-12-03T18:46:23.278981Z"}},"outputs":[{"name":"stdout","text":"Generated sequence: our with to i've how excited that remember i i well well a\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"model.save(\"transformer_model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:42:29.757717Z","iopub.execute_input":"2024-12-03T18:42:29.758072Z","iopub.status.idle":"2024-12-03T18:42:29.844947Z","shell.execute_reply.started":"2024-12-03T18:42:29.758041Z","shell.execute_reply":"2024-12-03T18:42:29.844237Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the model\nloaded_model = load_model(\"transformer_model.h5\", custom_objects={\n    \"TransformerBlock\": TransformerBlock,\n    \"PositionalEncoding\": PositionalEncoding\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:46:00.135157Z","iopub.execute_input":"2024-12-03T18:46:00.135686Z","iopub.status.idle":"2024-12-03T18:46:00.355050Z","shell.execute_reply.started":"2024-12-03T18:46:00.135652Z","shell.execute_reply":"2024-12-03T18:46:00.354375Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Embedding, Dropout, Dense, GlobalAveragePooling1D, LayerNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n\n# Build the model\nembed_dim = 128  # Embedding size\nnum_heads = 4   # Number of attention heads\nff_dim = 252    # Feed-forward network dimension\ndropout_rate = 0.5  # Dropout rate\n\ninputs = Input(shape=(max_length,))\nx = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\nx = PositionalEncoding(max_len=max_length, embed_dim=embed_dim)(x)\ntransformer_block = TransformerBlock(embed_dim, num_heads, ff_dim, rate=dropout_rate)\nx = transformer_block(x)\nx = GlobalAveragePooling1D()(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dropout(dropout_rate)(x)\n\noutputs = Dense(vocab_size, activation=\"softmax\")(x)\n\nmodel2 = Model(inputs=inputs, outputs=outputs)\nmodel2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nprint(model2.summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:47:47.996383Z","iopub.execute_input":"2024-12-03T18:47:47.996756Z","iopub.status.idle":"2024-12-03T18:47:48.263133Z","shell.execute_reply.started":"2024-12-03T18:47:47.996726Z","shell.execute_reply":"2024-12-03T18:47:48.262060Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m362,240\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_encoding_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m329,212\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2830\u001b[0m)           │       \u001b[38;5;34m183,950\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">362,240</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_encoding_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">329,212</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2830</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">183,950</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m883,658\u001b[0m (3.37 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">883,658</span> (3.37 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m883,658\u001b[0m (3.37 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">883,658</span> (3.37 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Train the model\nhistory = model2.fit(\n    X_train,\n    y_train,\n    batch_size=32,\n    epochs=100,\n    validation_data=(X_test, y_test)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:49:53.116210Z","iopub.execute_input":"2024-12-03T18:49:53.116994Z","iopub.status.idle":"2024-12-03T18:56:12.410359Z","shell.execute_reply.started":"2024-12-03T18:49:53.116959Z","shell.execute_reply":"2024-12-03T18:56:12.409611Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1189 - loss: 5.1228 - val_accuracy: 0.1190 - val_loss: 5.6952\nEpoch 2/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1256 - loss: 5.0777 - val_accuracy: 0.1192 - val_loss: 5.8469\nEpoch 3/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1315 - loss: 5.0384 - val_accuracy: 0.1287 - val_loss: 5.7776\nEpoch 4/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1318 - loss: 4.9635 - val_accuracy: 0.1277 - val_loss: 5.7194\nEpoch 5/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1362 - loss: 4.9229 - val_accuracy: 0.1303 - val_loss: 5.9414\nEpoch 6/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1419 - loss: 4.8591 - val_accuracy: 0.1334 - val_loss: 5.7801\nEpoch 7/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1391 - loss: 4.8285 - val_accuracy: 0.1322 - val_loss: 5.9815\nEpoch 8/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1439 - loss: 4.7881 - val_accuracy: 0.1379 - val_loss: 5.8750\nEpoch 9/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1506 - loss: 4.7482 - val_accuracy: 0.1400 - val_loss: 5.9939\nEpoch 10/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1528 - loss: 4.7252 - val_accuracy: 0.1432 - val_loss: 6.0336\nEpoch 11/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1521 - loss: 4.6772 - val_accuracy: 0.1451 - val_loss: 5.9950\nEpoch 12/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1529 - loss: 4.6601 - val_accuracy: 0.1498 - val_loss: 6.4768\nEpoch 13/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1584 - loss: 4.6014 - val_accuracy: 0.1510 - val_loss: 6.4412\nEpoch 14/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1613 - loss: 4.5455 - val_accuracy: 0.1545 - val_loss: 6.3061\nEpoch 15/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1618 - loss: 4.5508 - val_accuracy: 0.1491 - val_loss: 6.4346\nEpoch 16/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1597 - loss: 4.5398 - val_accuracy: 0.1565 - val_loss: 6.7252\nEpoch 17/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1677 - loss: 4.5082 - val_accuracy: 0.1615 - val_loss: 6.6599\nEpoch 18/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1652 - loss: 4.4636 - val_accuracy: 0.1616 - val_loss: 6.6915\nEpoch 19/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1680 - loss: 4.4703 - val_accuracy: 0.1629 - val_loss: 6.7689\nEpoch 20/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1742 - loss: 4.4356 - val_accuracy: 0.1590 - val_loss: 6.7678\nEpoch 21/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1744 - loss: 4.3942 - val_accuracy: 0.1650 - val_loss: 6.8862\nEpoch 22/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1765 - loss: 4.3942 - val_accuracy: 0.1661 - val_loss: 6.8352\nEpoch 23/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1796 - loss: 4.3668 - val_accuracy: 0.1690 - val_loss: 7.3530\nEpoch 24/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1819 - loss: 4.3426 - val_accuracy: 0.1687 - val_loss: 7.0145\nEpoch 25/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1804 - loss: 4.3423 - val_accuracy: 0.1670 - val_loss: 7.0848\nEpoch 26/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1844 - loss: 4.3122 - val_accuracy: 0.1681 - val_loss: 7.1475\nEpoch 27/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1844 - loss: 4.3012 - val_accuracy: 0.1695 - val_loss: 6.9858\nEpoch 28/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1876 - loss: 4.2747 - val_accuracy: 0.1700 - val_loss: 7.4242\nEpoch 29/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1878 - loss: 4.2572 - val_accuracy: 0.1718 - val_loss: 7.5647\nEpoch 30/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1900 - loss: 4.2603 - val_accuracy: 0.1720 - val_loss: 7.5083\nEpoch 31/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1884 - loss: 4.2572 - val_accuracy: 0.1723 - val_loss: 7.3401\nEpoch 32/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1915 - loss: 4.2392 - val_accuracy: 0.1737 - val_loss: 7.4599\nEpoch 33/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1970 - loss: 4.2151 - val_accuracy: 0.1712 - val_loss: 7.6977\nEpoch 34/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1976 - loss: 4.2028 - val_accuracy: 0.1714 - val_loss: 7.7858\nEpoch 35/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1940 - loss: 4.1960 - val_accuracy: 0.1699 - val_loss: 7.5039\nEpoch 36/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1932 - loss: 4.1822 - val_accuracy: 0.1761 - val_loss: 7.8655\nEpoch 37/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1951 - loss: 4.1625 - val_accuracy: 0.1754 - val_loss: 7.5014\nEpoch 38/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2009 - loss: 4.1568 - val_accuracy: 0.1751 - val_loss: 7.9665\nEpoch 39/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1963 - loss: 4.1491 - val_accuracy: 0.1778 - val_loss: 8.2392\nEpoch 40/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1986 - loss: 4.1437 - val_accuracy: 0.1769 - val_loss: 8.2928\nEpoch 41/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1994 - loss: 4.1340 - val_accuracy: 0.1776 - val_loss: 8.3107\nEpoch 42/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2016 - loss: 4.1161 - val_accuracy: 0.1753 - val_loss: 8.0491\nEpoch 43/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1998 - loss: 4.1380 - val_accuracy: 0.1819 - val_loss: 8.3324\nEpoch 44/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2050 - loss: 4.1064 - val_accuracy: 0.1731 - val_loss: 8.2266\nEpoch 45/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2004 - loss: 4.1073 - val_accuracy: 0.1798 - val_loss: 8.2436\nEpoch 46/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2099 - loss: 4.0801 - val_accuracy: 0.1769 - val_loss: 8.3706\nEpoch 47/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2106 - loss: 4.0734 - val_accuracy: 0.1780 - val_loss: 8.6046\nEpoch 48/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2060 - loss: 4.0850 - val_accuracy: 0.1795 - val_loss: 8.1005\nEpoch 49/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2069 - loss: 4.0656 - val_accuracy: 0.1757 - val_loss: 8.4256\nEpoch 50/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2095 - loss: 4.0375 - val_accuracy: 0.1779 - val_loss: 8.5515\nEpoch 51/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2135 - loss: 4.0211 - val_accuracy: 0.1811 - val_loss: 8.2448\nEpoch 52/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2100 - loss: 4.0627 - val_accuracy: 0.1804 - val_loss: 8.7090\nEpoch 53/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2149 - loss: 4.0222 - val_accuracy: 0.1813 - val_loss: 8.8253\nEpoch 54/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2132 - loss: 4.0152 - val_accuracy: 0.1822 - val_loss: 9.0233\nEpoch 55/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2145 - loss: 4.0090 - val_accuracy: 0.1774 - val_loss: 9.2706\nEpoch 56/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2140 - loss: 4.0174 - val_accuracy: 0.1794 - val_loss: 9.1457\nEpoch 57/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2155 - loss: 3.9872 - val_accuracy: 0.1794 - val_loss: 9.6764\nEpoch 58/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2160 - loss: 4.0027 - val_accuracy: 0.1795 - val_loss: 9.3119\nEpoch 59/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2136 - loss: 4.0089 - val_accuracy: 0.1785 - val_loss: 9.1323\nEpoch 60/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2181 - loss: 3.9757 - val_accuracy: 0.1804 - val_loss: 8.9031\nEpoch 61/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2123 - loss: 4.0172 - val_accuracy: 0.1782 - val_loss: 8.7616\nEpoch 62/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2161 - loss: 3.9870 - val_accuracy: 0.1797 - val_loss: 9.0655\nEpoch 63/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2153 - loss: 3.9600 - val_accuracy: 0.1787 - val_loss: 10.2690\nEpoch 64/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2183 - loss: 3.9744 - val_accuracy: 0.1769 - val_loss: 9.0256\nEpoch 65/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2182 - loss: 3.9510 - val_accuracy: 0.1799 - val_loss: 9.4074\nEpoch 66/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2192 - loss: 3.9551 - val_accuracy: 0.1781 - val_loss: 9.8441\nEpoch 67/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2163 - loss: 3.9764 - val_accuracy: 0.1819 - val_loss: 9.2166\nEpoch 68/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2166 - loss: 3.9701 - val_accuracy: 0.1818 - val_loss: 9.4070\nEpoch 69/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2231 - loss: 3.9384 - val_accuracy: 0.1776 - val_loss: 10.5812\nEpoch 70/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2179 - loss: 3.9711 - val_accuracy: 0.1821 - val_loss: 9.4612\nEpoch 71/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2163 - loss: 3.9292 - val_accuracy: 0.1818 - val_loss: 9.5979\nEpoch 72/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2167 - loss: 3.9421 - val_accuracy: 0.1802 - val_loss: 8.9880\nEpoch 73/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2211 - loss: 3.9465 - val_accuracy: 0.1809 - val_loss: 9.9257\nEpoch 74/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2221 - loss: 3.9134 - val_accuracy: 0.1822 - val_loss: 10.0607\nEpoch 75/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2226 - loss: 3.9224 - val_accuracy: 0.1800 - val_loss: 9.7528\nEpoch 76/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2235 - loss: 3.9152 - val_accuracy: 0.1830 - val_loss: 9.7550\nEpoch 77/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2242 - loss: 3.9036 - val_accuracy: 0.1829 - val_loss: 10.0506\nEpoch 78/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2242 - loss: 3.8983 - val_accuracy: 0.1824 - val_loss: 10.0104\nEpoch 79/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2235 - loss: 3.9075 - val_accuracy: 0.1773 - val_loss: 9.4204\nEpoch 80/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2280 - loss: 3.8705 - val_accuracy: 0.1815 - val_loss: 10.3073\nEpoch 81/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2294 - loss: 3.8847 - val_accuracy: 0.1803 - val_loss: 10.2080\nEpoch 82/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2276 - loss: 3.8761 - val_accuracy: 0.1788 - val_loss: 9.7927\nEpoch 83/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2262 - loss: 3.8801 - val_accuracy: 0.1805 - val_loss: 9.3936\nEpoch 84/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2278 - loss: 3.8870 - val_accuracy: 0.1831 - val_loss: 10.1037\nEpoch 85/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2267 - loss: 3.8929 - val_accuracy: 0.1830 - val_loss: 10.5453\nEpoch 86/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2301 - loss: 3.8742 - val_accuracy: 0.1807 - val_loss: 10.3543\nEpoch 87/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2259 - loss: 3.8886 - val_accuracy: 0.1830 - val_loss: 9.7048\nEpoch 88/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2222 - loss: 3.9140 - val_accuracy: 0.1813 - val_loss: 9.8413\nEpoch 89/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2288 - loss: 3.8701 - val_accuracy: 0.1834 - val_loss: 10.4204\nEpoch 90/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2255 - loss: 3.8817 - val_accuracy: 0.1838 - val_loss: 10.5775\nEpoch 91/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2314 - loss: 3.8479 - val_accuracy: 0.1822 - val_loss: 9.4828\nEpoch 92/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2296 - loss: 3.8350 - val_accuracy: 0.1834 - val_loss: 10.5167\nEpoch 93/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2305 - loss: 3.8339 - val_accuracy: 0.1843 - val_loss: 11.3806\nEpoch 94/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2368 - loss: 3.8280 - val_accuracy: 0.1870 - val_loss: 10.9815\nEpoch 95/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2346 - loss: 3.8325 - val_accuracy: 0.1824 - val_loss: 10.5562\nEpoch 96/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2339 - loss: 3.8351 - val_accuracy: 0.1779 - val_loss: 9.3955\nEpoch 97/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2326 - loss: 3.8422 - val_accuracy: 0.1824 - val_loss: 11.4556\nEpoch 98/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2375 - loss: 3.8157 - val_accuracy: 0.1818 - val_loss: 10.8683\nEpoch 99/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2326 - loss: 3.8226 - val_accuracy: 0.1846 - val_loss: 10.0318\nEpoch 100/100\n\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2348 - loss: 3.8189 - val_accuracy: 0.1848 - val_loss: 10.6695\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"\ninitial_text = \"I've been feeling so sad and\"\ngenerated_sequence = predict_sequence(initial_text, model, tokenizer, max_length, num_predictions=20)\nprint(f\"Generated sequence: {generated_sequence}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:56:51.457557Z","iopub.execute_input":"2024-12-03T18:56:51.457906Z","iopub.status.idle":"2024-12-03T18:56:52.447002Z","shell.execute_reply.started":"2024-12-03T18:56:51.457876Z","shell.execute_reply":"2024-12-03T18:56:52.446081Z"}},"outputs":[{"name":"stdout","text":"Generated sequence: our with to i've how excited that remember i i well well a\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"\ninitial_text = \"I've been feeling so sad and\"\ngenerated_sequence = predict_sequence(initial_text, model2, tokenizer, max_length, num_predictions=20)\nprint(f\"Generated sequence: {generated_sequence}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:56:54.038135Z","iopub.execute_input":"2024-12-03T18:56:54.038503Z","iopub.status.idle":"2024-12-03T18:56:55.012795Z","shell.execute_reply.started":"2024-12-03T18:56:54.038472Z","shell.execute_reply":"2024-12-03T18:56:55.011898Z"}},"outputs":[{"name":"stdout","text":"Generated sequence: have feel can been be feeling a sense sense of of sense failure\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}